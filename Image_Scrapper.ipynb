{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Webpage URL here : https://en.wikipedia.org/wiki/Bangalore\n"
     ]
    }
   ],
   "source": [
    "url = input('Enter the Webpage URL here : ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Library is used to requests for the HTML Structure of the website\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4 also called BeautifulSoup is used to make the code extracted from the webpage look more Readable\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using the various Regular Expression Libraries\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Name of the Website is: en.wikipedia.org\n"
     ]
    }
   ],
   "source": [
    "# Requesting the Html Code for the Webpage using the URL\n",
    "try:\n",
    "    res = requests.get(url)\n",
    "except:\n",
    "    print(\"The URL is not Responding\")\n",
    "result = re.search('https://(.*?)/',url)\n",
    "name = result.group(1)\n",
    "print('The Name of the Website is: '+name)\n",
    "\n",
    "# Making The Code Look more Readable\n",
    "soup = bs4.BeautifulSoup(res.text,\"lxml\")\n",
    "src_list = list()\n",
    "images = soup.select('img')\n",
    "\n",
    "# To Prevent the Kernel from Crashing we can only Download 200 images max from a webpage, The count variable will make sure of that\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Total Number of Image Tags Extracted are : 126 \n",
      "\n",
      "<img alt=\"Page semi-protected\" data-file-height=\"512\" data-file-width=\"512\" decoding=\"async\" height=\"20\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/1/1b/Semi-protection-shackle.svg/20px-Semi-protection-shackle.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/1/1b/Semi-protection-shackle.svg/30px-Semi-protection-shackle.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/1/1b/Semi-protection-shackle.svg/40px-Semi-protection-shackle.svg.png 2x\" width=\"20\"/> \n",
      "\n",
      "<img alt=\"UB City at night .jpg\" data-file-height=\"3032\" data-file-width=\"4048\" decoding=\"async\" height=\"202\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/23/UB_City_at_night_.jpg/270px-UB_City_at_night_.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/23/UB_City_at_night_.jpg/405px-UB_City_at_night_.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/23/UB_City_at_night_.jpg/540px-UB_City_at_night_.jpg 2x\" width=\"270\"/> \n",
      "\n",
      "<img alt=\"Bangalore India.jpg\" data-file-height=\"458\" data-file-width=\"640\" decoding=\"async\" height=\"96\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Bangalore_India.jpg/134px-Bangalore_India.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Bangalore_India.jpg/201px-Bangalore_India.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Bangalore_India.jpg/268px-Bangalore_India.jpg 2x\" width=\"134\"/> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gives A Count of the Total Image Tags in the html Script\n",
    "img_count= 0 \n",
    "for x in images:    \n",
    "    img_count = img_count+1\n",
    "    \n",
    "print('\\n\\nThe Total Number of Image Tags Extracted are : '+str(img_count),'\\n')\n",
    "\n",
    "# To  View the structure of the first 3 image tags \n",
    "for x in range(0,3):\n",
    "    print(images[x],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Once we know the location of the Source we can accordingly isolate the source links from the Image Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Bangalore_India.jpg/134px-Bangalore_India.jpg \n",
      "\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/47/BangaloreInfosys.jpg/134px-BangaloreInfosys.jpg \n",
      "\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/7/78/Lalbagh_Glasshouse_night_panorama.jpg/134px-Lalbagh_Glasshouse_night_panorama.jpg \n",
      "\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Bangalore_Palace_-_Jayamahal.jpg/134px-Bangalore_Palace_-_Jayamahal.jpg \n",
      "\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Bangalore_street_Map.png/250px-Bangalore_street_Map.png \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracts all the source Links from the images\n",
    "try:\n",
    "    for x in range(2,len(images)):\n",
    "        image = images[x]\n",
    "        src_list.append(image['src'])\n",
    "except:\n",
    "    print('Invalid')\n",
    "\n",
    "# To View the source of the image tags\n",
    "for x in range(0,5):\n",
    "    print(src_list[x],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Number 1 Has been Downloaded !! :)\n",
      "Image Number 2 Has been Downloaded !! :)\n",
      "Image Number 3 Has been Downloaded !! :)\n",
      "Image Number 4 Has been Downloaded !! :)\n",
      "Image Number 5 Has been Downloaded !! :)\n",
      "Image Number 6 Has been Downloaded !! :)\n",
      "Image Number 7 Has been Downloaded !! :)\n",
      "Image Number 8 Has been Downloaded !! :)\n",
      "Image Number 9 Has been Downloaded !! :)\n",
      "Image Number 10 Has been Downloaded !! :)\n",
      "Image Number 11 Has been Downloaded !! :)\n",
      "Image Number 12 Has been Downloaded !! :)\n",
      "Image Number 13 Has been Downloaded !! :)\n",
      "Image Number 14 Has been Downloaded !! :)\n",
      "Image Number 15 Has been Downloaded !! :)\n"
     ]
    }
   ],
   "source": [
    "# Loop will Iteraate over all the Source Links and Download all the Images Present in the webpage \n",
    "error = list()\n",
    "# For Now we will just download 15 images \n",
    "for x in range(0,15):\n",
    "    try:\n",
    "        # If the image is in .jpg format\n",
    "        if('.jpg' in src_list[x]):\n",
    "            if('https'not in src_list[x]):\n",
    "                image_link = requests.get('https:'+src_list[x])\n",
    "            else:\n",
    "                image_link = requests.get(src_list[x])\n",
    "            f = open('C:/Users/Arafat/Desktop/Image Scrapper/Scrapped Images/image'+str(x+1)+'.jpg','wb')\n",
    "            f.write(image_link.content)\n",
    "            f.close()\n",
    "            \n",
    "        # If the image is in .png format\n",
    "        elif('.png' in src_list[x]):\n",
    "            if('https'not in src_list[x]):\n",
    "                image_link = requests.get('https:'+src_list[x])\n",
    "            else:\n",
    "                image_link = requests.get(src_list[x])\n",
    "            f = open('C:/Users/Arafat/Desktop/Image Scrapper/Scrapped Images/image'+str(x+1)+'.png','wb')\n",
    "            f.write(image_link.content)\n",
    "            f.close()\n",
    "            \n",
    "        # If the image is in .gif format\n",
    "        else:\n",
    "            if('https'not in src_list[x]):\n",
    "                image_link = requests.get('https:'+src_list[x])\n",
    "            else:\n",
    "                image_link = requests.get(src_list[x])\n",
    "            f = open('C:/Users/Arafat/Desktop/Image Scrapper/Scrapped Images/image'+str(x+1)+'.gif','wb')\n",
    "            f.write(image_link.content)\n",
    "            f.close()\n",
    "    except:\n",
    "        print('The Image Source URL no '+str(x+1)+' Extracted From the WebPage is Invalid :(')\n",
    "    else:\n",
    "        print('Image Number '+str(x+1)+' Has been Downloaded !! :)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
